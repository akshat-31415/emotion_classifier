{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eec5dac-4bd9-4da3-a437-c8412d231790",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "775589bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(\":)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79268b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "output_path = \"mfcc_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=40, max_len=216):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    # Normalize length\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "print(\":)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5051e47-42e6-4c94-b686-97b4cdf057b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "extract_mfcc(\"03-01-07-01-02-02-01.wav\")\n",
    "print(\":)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89bfe42a-f540-488c-8412-044fba9e0ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `mfcc` is a 2D NumPy array (shape: [n_mfcc, time_frames])\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(extract_mfcc(\"03-01-07-01-02-02-01.wav\"), x_axis='time')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"MFCC\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541635e7-67e1-4492-8d68-c17f16d4f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(file_path, save_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "887a6b10-c91e-4a61-8513-1d4aaa6081cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_spectrogram(\"03-01-07-01-02-02-01.wav\",\"spectrogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f51c746-38af-4e8e-8b74-de1753241423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/emotion_env/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  Dogs are sitting by the door.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")  # or \"small\", \"medium\", \"large\"\n",
    "\n",
    "result = model.transcribe(\"03-01-07-01-02-02-01.wav\")\n",
    "print(\"Transcription:\", result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaebcece-ba72-4375-9a4a-f739a8b7de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Using cached openai-whisper-20240930.tar.gz (800 kB)\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (2.2.5)\n",
      "Requirement already satisfied: torch in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (4.67.1)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: triton>=2.0.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from triton>=2.0.0->openai-whisper) (78.1.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (1.11.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m299.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?2done\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=c1afae0832265cd72746baa09a84880d7035533fc9fa031bc84978004e1f3cfa\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, tiktoken, openai-whisper\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [openai-whisper]━━━\u001b[0m \u001b[32m2/3\u001b[0m [openai-whisper]\n",
      "\u001b[1A\u001b[2KSuccessfully installed more-itertools-10.7.0 openai-whisper-20240930 tiktoken-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f158d12-8949-4a0f-9a26-e31202ba643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set paths\n",
    "dataset_path = \"voice_dataset\"\n",
    "output_path = \"mfcc_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=40, max_len=216):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Pad or truncate to fixed length for uniform input\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "i=0\n",
    "# Traverse all actors and wav files\n",
    "for root, _, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                mfcc = extract_mfcc(file_path)\n",
    "                label = file.split(\"-\")[2]  # Emotion label\n",
    "                save_name = file.replace(\".wav\", \".npy\")\n",
    "                print(i+1);\n",
    "                i+=1;\n",
    "                np.save(os.path.join(output_path, save_name), mfcc)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {file} due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "695aaf41-2e4b-4c7c-9a26-e428e94d0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = np.load(self.file_paths[idx])  # (n_mfcc, time)\n",
    "        mfcc = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)  # (1, n_mfcc, time)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return mfcc, label\n",
    "\n",
    "# Load file paths & labels\n",
    "data_dir = \"mfcc_data\"\n",
    "file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".npy\")]\n",
    "labels = [int(os.path.basename(f).split(\"-\")[2]) - 1 for f in file_paths]  # 0-indexed emotions\n",
    "\n",
    "# Train/val split\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(file_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = MFCCDataset(train_files, train_labels)\n",
    "val_dataset = MFCCDataset(val_files, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "116f1866-b05d-4d73-890b-888d74d8860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEmotionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Placeholder for dynamically determining flatten size\n",
    "        self.flattened_size = None\n",
    "\n",
    "        # Define dummy input to infer size\n",
    "        self._init_linear_layer()\n",
    "\n",
    "    def _init_linear_layer(self):\n",
    "        # Dummy forward to calculate size after conv layers\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 40, 216)  # typical MFCC shape\n",
    "            x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            self.flattened_size = x.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87c219bb-0b7b-45a1-a20c-7f2572206863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8942.6067, Train Acc: 0.1337\n",
      "Epoch 2, Loss: 2229.1072, Train Acc: 0.2752\n",
      "Epoch 3, Loss: 1915.7588, Train Acc: 0.3941\n",
      "Epoch 4, Loss: 1614.9838, Train Acc: 0.5017\n",
      "Epoch 5, Loss: 1327.6346, Train Acc: 0.5972\n",
      "Epoch 6, Loss: 1143.4154, Train Acc: 0.6571\n",
      "Epoch 7, Loss: 825.3029, Train Acc: 0.7500\n",
      "Epoch 8, Loss: 542.3569, Train Acc: 0.8472\n",
      "Epoch 9, Loss: 291.0340, Train Acc: 0.9314\n",
      "Epoch 10, Loss: 147.7643, Train Acc: 0.9714\n",
      "Epoch 11, Loss: 131.2673, Train Acc: 0.9757\n",
      "Epoch 12, Loss: 99.2888, Train Acc: 0.9757\n",
      "Epoch 13, Loss: 57.3548, Train Acc: 0.9887\n",
      "Epoch 14, Loss: 68.2726, Train Acc: 0.9826\n",
      "Epoch 15, Loss: 62.9579, Train Acc: 0.9878\n",
      "Epoch 16, Loss: 34.6086, Train Acc: 0.9931\n",
      "Epoch 17, Loss: 37.1944, Train Acc: 0.9939\n",
      "Epoch 18, Loss: 39.1976, Train Acc: 0.9931\n",
      "Epoch 19, Loss: 20.2960, Train Acc: 0.9965\n",
      "Epoch 20, Loss: 22.7353, Train Acc: 0.9948\n",
      "Epoch 21, Loss: 25.7730, Train Acc: 0.9939\n",
      "Epoch 22, Loss: 45.5116, Train Acc: 0.9870\n",
      "Epoch 23, Loss: 45.7161, Train Acc: 0.9878\n",
      "Epoch 24, Loss: 26.5861, Train Acc: 0.9948\n",
      "Epoch 25, Loss: 11.8824, Train Acc: 0.9991\n",
      "Epoch 26, Loss: 27.7837, Train Acc: 0.9931\n",
      "Epoch 27, Loss: 20.3600, Train Acc: 0.9948\n",
      "Epoch 28, Loss: 24.4819, Train Acc: 0.9922\n",
      "Epoch 29, Loss: 16.3317, Train Acc: 0.9983\n",
      "Epoch 30, Loss: 8.0264, Train Acc: 0.9991\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNEmotionModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "    train_acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9226b8ce-f581-485f-995f-be518ec7f60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4167\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "val_acc = correct / len(val_dataset)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f3695-8fe0-42d1-8dec-96bccbc07dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705374de-9684-402e-8ab4-58b6fec739ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepCNNEmotionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNNEmotionModel, self).__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        # Compute the flattened feature size after 3 poolings\n",
    "        # Starting from (1, 40, 216) → (128, 5, 27)\n",
    "        self.fc1 = nn.Linear(128 * 5 * 27, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4d4ae39-98a4-459a-b40b-d6d10174aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8834.0464, Train Acc: 0.1380\n",
      "Epoch 2, Loss: 2395.4630, Train Acc: 0.1372\n",
      "Epoch 3, Loss: 2277.7856, Train Acc: 0.2092\n",
      "Epoch 4, Loss: 1845.8404, Train Acc: 0.4158\n",
      "Epoch 5, Loss: 1379.1804, Train Acc: 0.5720\n",
      "Epoch 6, Loss: 1003.8470, Train Acc: 0.7023\n",
      "Epoch 7, Loss: 697.6840, Train Acc: 0.8021\n",
      "Epoch 8, Loss: 416.7323, Train Acc: 0.8845\n",
      "Epoch 9, Loss: 272.7730, Train Acc: 0.9314\n",
      "Epoch 10, Loss: 177.8911, Train Acc: 0.9575\n",
      "Epoch 11, Loss: 138.2193, Train Acc: 0.9722\n",
      "Epoch 12, Loss: 91.5216, Train Acc: 0.9809\n",
      "Epoch 13, Loss: 52.7259, Train Acc: 0.9922\n",
      "Epoch 14, Loss: 42.9813, Train Acc: 0.9939\n",
      "Epoch 15, Loss: 28.3471, Train Acc: 0.9983\n",
      "Epoch 16, Loss: 51.8334, Train Acc: 0.9861\n",
      "Epoch 17, Loss: 65.9471, Train Acc: 0.9922\n",
      "Epoch 18, Loss: 29.2266, Train Acc: 0.9965\n",
      "Epoch 19, Loss: 23.2028, Train Acc: 0.9948\n",
      "Epoch 20, Loss: 26.2233, Train Acc: 0.9939\n",
      "Epoch 21, Loss: 24.2076, Train Acc: 0.9957\n",
      "Epoch 22, Loss: 24.7418, Train Acc: 0.9922\n",
      "Epoch 23, Loss: 28.1271, Train Acc: 0.9939\n",
      "Epoch 24, Loss: 20.7969, Train Acc: 0.9948\n",
      "Epoch 25, Loss: 29.8077, Train Acc: 0.9931\n",
      "Epoch 26, Loss: 23.3891, Train Acc: 0.9965\n",
      "Epoch 27, Loss: 22.4879, Train Acc: 0.9948\n",
      "Epoch 28, Loss: 18.3603, Train Acc: 0.9939\n",
      "Epoch 29, Loss: 12.9690, Train Acc: 0.9983\n",
      "Epoch 30, Loss: 23.9757, Train Acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNEmotionModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "    train_acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c531a4e2-bede-4dfe-aabb-2b688d62d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3785\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "val_acc = correct / len(val_dataset)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d9789-d2cd-4273-a306-0b4d578e1d31",
   "metadata": {},
   "source": [
    "import whisper\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Define synthetic sentences\n",
    "emotion_map = {\n",
    "    \"01\": \"I am speaking in a neutral tone.\",\n",
    "    \"02\": \"I am calm and composed.\",\n",
    "    \"03\": \"I feel very happy today!\",\n",
    "    \"04\": \"I feel so down today.\",\n",
    "    \"05\": \"I am furious right now!\",\n",
    "    \"06\": \"I am really scared.\",\n",
    "    \"07\": \"This is so disgusting!\",\n",
    "    \"08\": \"I can't believe this happened!\"\n",
    "}\n",
    "\n",
    "# Extract emotion ID from filename\n",
    "def extract_emotion_id(filename):\n",
    "    try:\n",
    "        parts = filename.split(\"-\")\n",
    "        return parts[2]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Directory setup\n",
    "root_dir = \"voice_dataset\"\n",
    "output_file = \"transcripts_with_emotion.txt\"\n",
    "i=0\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for actor_dir in os.listdir(root_dir):\n",
    "        actor_path = os.path.join(root_dir, actor_dir)\n",
    "        if os.path.isdir(actor_path):\n",
    "            for file in os.listdir(actor_path):\n",
    "                if file.endswith(\".wav\") and not file.endswith(\".wav:Zone.Identifier\"):\n",
    "                    file_path = os.path.join(actor_path, file)\n",
    "                    try:\n",
    "                        result = model.transcribe(file_path)\n",
    "                        transcript = result[\"text\"].strip()\n",
    "                        \n",
    "                        # Use synthetic sentence if transcript is too short\n",
    "                        if len(transcript.split()) < 3:\n",
    "                            emotion_id = extract_emotion_id(file)\n",
    "                            transcript = emotion_map.get(emotion_id, \"[UNKNOWN EMOTION]\")\n",
    "                            print(f\" → Replaced with synthetic: {transcript}\")\n",
    "                        \n",
    "                        out_f.write(f\"{file_path}\\t{transcript}\\n\")\n",
    "                        if(i%20==0):\n",
    "                            print(str((i+1)/1440) + \"% done\")\n",
    "                        i+=1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c753854a-5349-4404-b248-c9e314ad3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts = []\n",
    "# with open(\"transcripts_with_emotion.txt\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         filename, *text = line.strip().split()\n",
    "#         transcripts.append({\n",
    "#             \"filename\": filename,\n",
    "#             \"text\": \" \".join(text)\n",
    "#         })\n",
    "transcripts = []\n",
    "with open(\"transcripts_with_emotion.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        filepath, *text = line.strip().split()\n",
    "        transcripts.append({\n",
    "            \"filename\": filepath,   # The path to the audio file\n",
    "            \"text\": \" \".join(text)   # The transcribed text from the audio\n",
    "        })\n",
    "\n",
    "# If you want to assign a label (for example, assuming you have a predefined emotion per file)\n",
    "# You can create a dummy label or load emotion labels if available for each file.\n",
    "# Let's assume you have labels manually, for now:\n",
    "\n",
    "# Example of adding labels\n",
    "emotion_labels = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'calm', 'disgust', 'surprised']  # Modify as needed\n",
    "for idx, entry in enumerate(transcripts):\n",
    "    entry['label'] = emotion_labels[idx % len(emotion_labels)]  # Dummy label assignment based on index\n",
    "\n",
    "# Now 'data' will contain the text and its corresponding label:\n",
    "data = [{\"text\": entry[\"text\"], \"label\": entry[\"label\"]} for entry in transcripts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20d7916-94df-435b-8e75-767cc2e26e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion_map = {\n",
    "#     \"01\": \"neutral\",\n",
    "#     \"02\": \"calm\",\n",
    "#     \"03\": \"happy\",\n",
    "#     \"04\": \"sad\",\n",
    "#     \"05\": \"angry\",\n",
    "#     \"06\": \"fearful\",\n",
    "#     \"07\": \"disgust\",\n",
    "#     \"08\": \"surprised\"\n",
    "# }\n",
    "\n",
    "# for entry in transcripts:\n",
    "#     emotion_code = entry[\"filename\"].split(\"-\")[2]\n",
    "#     entry[\"label\"] = emotion_map[emotion_code]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644c74f5-ee11-448c-879b-56dd2778393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [{\"text\": entry[\"text\"], \"label\": entry[\"label\"]} for entry in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "996a619c-371e-4e1a-a495-3d1fb2a00150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Simple tokenizer\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "# Build vocabulary\n",
    "def build_vocab(data, min_freq=2):\n",
    "    counter = Counter()\n",
    "    for item in data:\n",
    "        counter.update(tokenize(item[\"text\"]))\n",
    "    vocab = {word: i+2 for i, (word, count) in enumerate(counter.items()) if count >= min_freq}\n",
    "    vocab[\"<PAD>\"] = 0\n",
    "    vocab[\"<UNK>\"] = 1\n",
    "    return vocab\n",
    "\n",
    "# Convert text to indices\n",
    "def encode(text, vocab):\n",
    "    return [vocab.get(word, vocab[\"<UNK>\"]) for word in tokenize(text)]\n",
    "\n",
    "# Custom dataset\n",
    "class TextEmotionDataset(Dataset):\n",
    "    def __init__(self, data, vocab, label_encoder):\n",
    "        self.vocab = vocab\n",
    "        self.label_encoder = label_encoder\n",
    "        self.samples = [(torch.tensor(encode(item[\"text\"], vocab)), label_encoder.transform([item[\"label\"]])[0]) for item in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    return padded, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c70bff1-7e56-48a9-aeec-645cbd25e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, h_n = self.gru(embedded)\n",
    "        output = self.fc(h_n.squeeze(0))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4e43082-b167-4c71-8721-7beec587806a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_y)\n\u001b[1;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/emotion_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/emotion_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m, in \u001b[0;36mGRUClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     _, h_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(embedded)\n\u001b[1;32m     13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(h_n\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/emotion_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/emotion_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/emotion_env/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/emotion_env/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(emotion_labels)\n",
    "\n",
    "# Build vocab and dataset\n",
    "vocab = build_vocab(data)\n",
    "dataset = TextEmotionDataset(data, vocab, label_encoder)\n",
    "\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_data, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "# Model\n",
    "model = GRUClassifier(vocab_size=len(vocab), embedding_dim=100, hidden_dim=128, output_dim=len(label_encoder.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cec032-aaa1-4193-9e98-98aa9588717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        outputs = model(batch_x)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(batch_y.tolist())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20902efd-c178-45e0-a24a-9682f7f74869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (emotion_env)",
   "language": "python",
   "name": "emotion_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
