{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eec5dac-4bd9-4da3-a437-c8412d231790",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "775589bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79268b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "output_path = \"mfcc_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=40, max_len=216):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    # Normalize length\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89bfe42a-f540-488c-8412-044fba9e0ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `mfcc` is a 2D NumPy array (shape: [n_mfcc, time_frames])\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(extract_mfcc(\"03-01-07-01-02-02-01.wav\"), x_axis='time')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"MFCC\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f51c746-38af-4e8e-8b74-de1753241423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/emotion_env/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  Dogs are sitting by the door.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")  # or \"small\", \"medium\", \"large\"\n",
    "\n",
    "result = model.transcribe(\"03-01-07-01-02-02-01.wav\")\n",
    "print(\"Transcription:\", result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaebcece-ba72-4375-9a4a-f739a8b7de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Using cached openai-whisper-20240930.tar.gz (800 kB)\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (2.2.5)\n",
      "Requirement already satisfied: torch in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (4.67.1)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: triton>=2.0.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from openai-whisper) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from triton>=2.0.0->openai-whisper) (78.1.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from torch->openai-whisper) (1.11.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/emotion_env/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m299.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?2done\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=c1afae0832265cd72746baa09a84880d7035533fc9fa031bc84978004e1f3cfa\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, tiktoken, openai-whisper\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [openai-whisper]━━━\u001b[0m \u001b[32m2/3\u001b[0m [openai-whisper]\n",
      "\u001b[1A\u001b[2KSuccessfully installed more-itertools-10.7.0 openai-whisper-20240930 tiktoken-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f158d12-8949-4a0f-9a26-e31202ba643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set paths\n",
    "dataset_path = \"voice_dataset\"\n",
    "output_path = \"mfcc_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=40, max_len=216):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "    # Pad or truncate to fixed length for uniform input\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "i=0\n",
    "# Traverse all actors and wav files\n",
    "for root, _, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                mfcc = extract_mfcc(file_path)\n",
    "                label = file.split(\"-\")[2]  # Emotion label\n",
    "                save_name = file.replace(\".wav\", \".npy\")\n",
    "                # print(i+1);\n",
    "                # i+=1;\n",
    "                np.save(os.path.join(output_path, save_name), mfcc)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {file} due to error: {e}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "695aaf41-2e4b-4c7c-9a26-e428e94d0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = np.load(self.file_paths[idx])  # (n_mfcc, time)\n",
    "        mfcc = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)  # (1, n_mfcc, time)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return mfcc, label\n",
    "\n",
    "# Load file paths & labels\n",
    "data_dir = \"mfcc_data\"\n",
    "file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".npy\")]\n",
    "labels = [int(os.path.basename(f).split(\"-\")[2]) - 1 for f in file_paths]  # 0-indexed emotions\n",
    "\n",
    "# Train/val split\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(file_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = MFCCDataset(train_files, train_labels)\n",
    "val_dataset = MFCCDataset(val_files, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "116f1866-b05d-4d73-890b-888d74d8860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEmotionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Placeholder for dynamically determining flatten size\n",
    "        self.flattened_size = None\n",
    "\n",
    "        # Define dummy input to infer size\n",
    "        self._init_linear_layer()\n",
    "\n",
    "    def _init_linear_layer(self):\n",
    "        # Dummy forward to calculate size after conv layers\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 40, 216)  # typical MFCC shape\n",
    "            x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            self.flattened_size = x.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87c219bb-0b7b-45a1-a20c-7f2572206863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8942.6067, Train Acc: 0.1337\n",
      "Epoch 2, Loss: 2229.1072, Train Acc: 0.2752\n",
      "Epoch 3, Loss: 1915.7588, Train Acc: 0.3941\n",
      "Epoch 4, Loss: 1614.9838, Train Acc: 0.5017\n",
      "Epoch 5, Loss: 1327.6346, Train Acc: 0.5972\n",
      "Epoch 6, Loss: 1143.4154, Train Acc: 0.6571\n",
      "Epoch 7, Loss: 825.3029, Train Acc: 0.7500\n",
      "Epoch 8, Loss: 542.3569, Train Acc: 0.8472\n",
      "Epoch 9, Loss: 291.0340, Train Acc: 0.9314\n",
      "Epoch 10, Loss: 147.7643, Train Acc: 0.9714\n",
      "Epoch 11, Loss: 131.2673, Train Acc: 0.9757\n",
      "Epoch 12, Loss: 99.2888, Train Acc: 0.9757\n",
      "Epoch 13, Loss: 57.3548, Train Acc: 0.9887\n",
      "Epoch 14, Loss: 68.2726, Train Acc: 0.9826\n",
      "Epoch 15, Loss: 62.9579, Train Acc: 0.9878\n",
      "Epoch 16, Loss: 34.6086, Train Acc: 0.9931\n",
      "Epoch 17, Loss: 37.1944, Train Acc: 0.9939\n",
      "Epoch 18, Loss: 39.1976, Train Acc: 0.9931\n",
      "Epoch 19, Loss: 20.2960, Train Acc: 0.9965\n",
      "Epoch 20, Loss: 22.7353, Train Acc: 0.9948\n",
      "Epoch 21, Loss: 25.7730, Train Acc: 0.9939\n",
      "Epoch 22, Loss: 45.5116, Train Acc: 0.9870\n",
      "Epoch 23, Loss: 45.7161, Train Acc: 0.9878\n",
      "Epoch 24, Loss: 26.5861, Train Acc: 0.9948\n",
      "Epoch 25, Loss: 11.8824, Train Acc: 0.9991\n",
      "Epoch 26, Loss: 27.7837, Train Acc: 0.9931\n",
      "Epoch 27, Loss: 20.3600, Train Acc: 0.9948\n",
      "Epoch 28, Loss: 24.4819, Train Acc: 0.9922\n",
      "Epoch 29, Loss: 16.3317, Train Acc: 0.9983\n",
      "Epoch 30, Loss: 8.0264, Train Acc: 0.9991\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNEmotionModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "    train_acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9226b8ce-f581-485f-995f-be518ec7f60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4167\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "val_acc = correct / len(val_dataset)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f3695-8fe0-42d1-8dec-96bccbc07dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705374de-9684-402e-8ab4-58b6fec739ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepCNNEmotionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNNEmotionModel, self).__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        # Compute the flattened feature size after 3 poolings\n",
    "        # Starting from (1, 40, 216) → (128, 5, 27)\n",
    "        self.fc1 = nn.Linear(128 * 5 * 27, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4d4ae39-98a4-459a-b40b-d6d10174aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8834.0464, Train Acc: 0.1380\n",
      "Epoch 2, Loss: 2395.4630, Train Acc: 0.1372\n",
      "Epoch 3, Loss: 2277.7856, Train Acc: 0.2092\n",
      "Epoch 4, Loss: 1845.8404, Train Acc: 0.4158\n",
      "Epoch 5, Loss: 1379.1804, Train Acc: 0.5720\n",
      "Epoch 6, Loss: 1003.8470, Train Acc: 0.7023\n",
      "Epoch 7, Loss: 697.6840, Train Acc: 0.8021\n",
      "Epoch 8, Loss: 416.7323, Train Acc: 0.8845\n",
      "Epoch 9, Loss: 272.7730, Train Acc: 0.9314\n",
      "Epoch 10, Loss: 177.8911, Train Acc: 0.9575\n",
      "Epoch 11, Loss: 138.2193, Train Acc: 0.9722\n",
      "Epoch 12, Loss: 91.5216, Train Acc: 0.9809\n",
      "Epoch 13, Loss: 52.7259, Train Acc: 0.9922\n",
      "Epoch 14, Loss: 42.9813, Train Acc: 0.9939\n",
      "Epoch 15, Loss: 28.3471, Train Acc: 0.9983\n",
      "Epoch 16, Loss: 51.8334, Train Acc: 0.9861\n",
      "Epoch 17, Loss: 65.9471, Train Acc: 0.9922\n",
      "Epoch 18, Loss: 29.2266, Train Acc: 0.9965\n",
      "Epoch 19, Loss: 23.2028, Train Acc: 0.9948\n",
      "Epoch 20, Loss: 26.2233, Train Acc: 0.9939\n",
      "Epoch 21, Loss: 24.2076, Train Acc: 0.9957\n",
      "Epoch 22, Loss: 24.7418, Train Acc: 0.9922\n",
      "Epoch 23, Loss: 28.1271, Train Acc: 0.9939\n",
      "Epoch 24, Loss: 20.7969, Train Acc: 0.9948\n",
      "Epoch 25, Loss: 29.8077, Train Acc: 0.9931\n",
      "Epoch 26, Loss: 23.3891, Train Acc: 0.9965\n",
      "Epoch 27, Loss: 22.4879, Train Acc: 0.9948\n",
      "Epoch 28, Loss: 18.3603, Train Acc: 0.9939\n",
      "Epoch 29, Loss: 12.9690, Train Acc: 0.9983\n",
      "Epoch 30, Loss: 23.9757, Train Acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNEmotionModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "    train_acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c531a4e2-bede-4dfe-aabb-2b688d62d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3785\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(1) == targets).sum().item()\n",
    "\n",
    "val_acc = correct / len(val_dataset)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e53e1-d571-4c59-9ec2-26417a0169d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Define synthetic sentences\n",
    "emotion_map = {\n",
    "    \"01\": \"I am speaking in a neutral tone.\",\n",
    "    \"02\": \"I am calm and composed.\",\n",
    "    \"03\": \"I feel very happy today!\",\n",
    "    \"04\": \"I feel so down today.\",\n",
    "    \"05\": \"I am furious right now!\",\n",
    "    \"06\": \"I am really scared.\",\n",
    "    \"07\": \"This is so disgusting!\",\n",
    "    \"08\": \"I can't believe this happened!\"\n",
    "}\n",
    "\n",
    "# Extract emotion ID from filename\n",
    "def extract_emotion_id(filename):\n",
    "    try:\n",
    "        parts = filename.split(\"-\")\n",
    "        return parts[2]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Directory setup\n",
    "root_dir = \"voice_dataset\"\n",
    "output_file = \"transcripts_with_emotion.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for actor_dir in os.listdir(root_dir):\n",
    "        actor_path = os.path.join(root_dir, actor_dir)\n",
    "        if os.path.isdir(actor_path):\n",
    "            for file in os.listdir(actor_path):\n",
    "                if file.endswith(\".wav\") and not file.endswith(\".wav:Zone.Identifier\"):\n",
    "                    file_path = os.path.join(actor_path, file)\n",
    "                    try:\n",
    "                        result = model.transcribe(file_path)\n",
    "                        transcript = result[\"text\"].strip()\n",
    "                        \n",
    "                        # Use synthetic sentence if transcript is too short\n",
    "                        if len(transcript.split()) < 3:\n",
    "                            emotion_id = extract_emotion_id(file)\n",
    "                            transcript = emotion_map.get(emotion_id, \"[UNKNOWN EMOTION]\")\n",
    "                            print(f\" → Replaced with synthetic: {transcript}\")\n",
    "                        \n",
    "                        out_f.write(f\"{file_path}\\t{transcript}\\n\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20902efd-c178-45e0-a24a-9682f7f74869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Read and parse dataset\n",
    "def load_data(file_path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            path, *transcript = line.strip().split()\n",
    "            text = ' '.join(transcript)\n",
    "            emotion_id = int(path.split('/')[-1].split('-')[2])\n",
    "            # Map 1-8 to 0-7\n",
    "            label = emotion_id - 1\n",
    "            texts.append(text.lower())\n",
    "            labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "# Simple tokenizer and vocabulary builder\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(tokenize(text))\n",
    "    vocab = {word: i + 2 for i, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "    vocab['<pad>'] = 0\n",
    "    vocab['<unk>'] = 1\n",
    "    return vocab\n",
    "\n",
    "def encode(text, vocab, max_len=20):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab.get(token, vocab['<unk>']) for token in tokens[:max_len]]\n",
    "    return ids + [vocab['<pad>']] * (max_len - len(ids))\n",
    "\n",
    "# Dataset class\n",
    "class EmotionTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=20):\n",
    "        self.data = [encode(text, vocab, max_len) for text in texts]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "# GRU Model\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, hidden = self.gru(embedded)\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb264a0-a467-4b07-8062-f5c86f521c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0689\n",
      "Epoch 2, Loss: 2.0637\n",
      "Epoch 3, Loss: 2.0623\n",
      "Epoch 4, Loss: 2.0624\n",
      "Epoch 5, Loss: 2.0611\n",
      "Epoch 6, Loss: 2.0617\n",
      "Epoch 7, Loss: 2.0620\n",
      "Epoch 8, Loss: 2.0617\n",
      "Epoch 9, Loss: 2.0621\n",
      "Epoch 10, Loss: 2.0613\n"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "texts, labels = load_data('transcripts_with_emotion.txt')\n",
    "vocab = build_vocab(texts, min_freq=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = EmotionTextDataset(X_train, y_train, vocab)\n",
    "val_dataset = EmotionTextDataset(X_val, y_val, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GRUClassifier(vocab_size=len(vocab), embed_dim=64, hidden_dim=128, output_dim=8).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "for epoch in range(10):\n",
    "    loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "263cd28d-ebf6-440c-b844-eba2a450dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate_model(model, val_dataset, device):\n",
    "    model.eval()\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation Accuracy: {acc * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1c8677f-6a63-41cb-8a61-6c342527fa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 10.07%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, val_dataset, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (emotion_env)",
   "language": "python",
   "name": "emotion_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
